#!/usr/bin/env python3
"""
xsukax EN-AR Offline Translator API v2.2
Fixed version with proper formatting and complete translation
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import os
import sys
import logging
import re

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)  # Enable CORS for all routes

# Global variables for models and tokenizers
models = {}
tokenizers = {}

def load_models():
    """Load the translation models and tokenizers"""
    try:
        from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
        
        logger.info("Loading translation models...")
        
        # Check if models directory exists
        if not os.path.exists("models"):
            logger.error("Models directory not found. Please run install_dependencies.py first.")
            return False
        
        # Load English to Arabic model
        try:
            tokenizers['en-ar'] = AutoTokenizer.from_pretrained("models/en-ar-tokenizer")
            models['en-ar'] = AutoModelForSeq2SeqLM.from_pretrained("models/en-ar-model")
            logger.info("‚úì English to Arabic model loaded")
        except Exception as e:
            logger.error(f"Failed to load EN-AR model: {e}")
            return False
        
        # Load Arabic to English model
        try:
            tokenizers['ar-en'] = AutoTokenizer.from_pretrained("models/ar-en-tokenizer")
            models['ar-en'] = AutoModelForSeq2SeqLM.from_pretrained("models/ar-en-model")
            logger.info("‚úì Arabic to English model loaded")
        except Exception as e:
            logger.error(f"Failed to load AR-EN model: {e}")
            return False
        
        logger.info("üéâ All models loaded successfully!")
        return True
        
    except ImportError as e:
        logger.error(f"Missing required packages: {e}")
        logger.error("Please run install_dependencies.py first")
        return False
    except Exception as e:
        logger.error(f"Unexpected error loading models: {e}")
        return False

def clean_and_prepare_text(text):
    """Clean and prepare text for translation"""
    # Remove excessive whitespace but preserve structure
    lines = text.split('\n')
    cleaned_lines = []
    
    for line in lines:
        # Clean each line but preserve empty lines
        if line.strip():
            # Remove extra spaces within the line
            cleaned_line = ' '.join(line.split())
            cleaned_lines.append(cleaned_line)
        else:
            cleaned_lines.append('')
    
    return '\n'.join(cleaned_lines)

def split_text_smart(text, max_length=300):
    """Split text intelligently while preserving paragraphs and sentences"""
    
    # First split by double newlines (paragraphs)
    paragraphs = text.split('\n\n')
    chunks = []
    
    for paragraph in paragraphs:
        paragraph = paragraph.strip()
        if not paragraph:
            continue
            
        # If paragraph is short enough, keep as one chunk
        if len(paragraph) <= max_length:
            chunks.append(paragraph)
            continue
            
        # Split long paragraphs by sentences
        # Handle both English and Arabic sentence endings
        sentence_pattern = r'[.!?ÿü‡•§]+\s+'
        sentences = re.split(sentence_pattern, paragraph)
        
        current_chunk = ""
        
        for i, sentence in enumerate(sentences):
            sentence = sentence.strip()
            if not sentence:
                continue
                
            # Add sentence ending back (except for last sentence)
            if i < len(sentences) - 1:
                if re.search(r'[a-zA-Z]', sentence):  # English
                    sentence += '. '
                else:  # Arabic
                    sentence += 'ÿå '
            
            # Check if adding this sentence exceeds limit
            if len(current_chunk + sentence) > max_length and current_chunk:
                chunks.append(current_chunk.strip())
                current_chunk = sentence
            else:
                current_chunk += sentence
        
        if current_chunk.strip():
            chunks.append(current_chunk.strip())
    
    return chunks

def translate_chunk_robust(chunk, direction):
    """Robustly translate a single chunk"""
    try:
        if direction not in models or direction not in tokenizers:
            return None, "Invalid translation direction"
        
        chunk = chunk.strip()
        if not chunk:
            return "", None
        
        logger.info(f"Translating chunk: {chunk[:50]}..." if len(chunk) > 50 else f"Translating chunk: {chunk}")
        
        # Tokenize with proper settings
        inputs = tokenizers[direction](
            chunk,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=512
        )
        
        # Generate translation with optimized parameters
        outputs = models[direction].generate(
            inputs["input_ids"],
            max_length=512,
            min_length=1,
            num_beams=5,              # Increased beams for better quality
            early_stopping=True,
            no_repeat_ngram_size=3,
            length_penalty=1.2,       # Slight preference for longer outputs
            repetition_penalty=1.1,   # Reduce repetition
            do_sample=False,          # Deterministic
            pad_token_id=tokenizers[direction].pad_token_id,
            eos_token_id=tokenizers[direction].eos_token_id,
            forced_eos_token_id=tokenizers[direction].eos_token_id
        )
        
        # Decode the translation
        translation = tokenizers[direction].decode(outputs[0], skip_special_tokens=True)
        
        # Clean up the translation
        translation = translation.strip()
        
        # Validate translation (ensure it's not the same as input)
        if translation.lower() == chunk.lower():
            logger.warning(f"Translation same as input for chunk: {chunk[:30]}...")
            # Try again with different parameters
            outputs = models[direction].generate(
                inputs["input_ids"],
                max_length=512,
                num_beams=3,
                temperature=0.7,
                do_sample=True,
                early_stopping=True,
                pad_token_id=tokenizers[direction].pad_token_id
            )
            translation = tokenizers[direction].decode(outputs[0], skip_special_tokens=True).strip()
        
        logger.info(f"Translation result: {translation[:50]}..." if len(translation) > 50 else f"Translation result: {translation}")
        
        return translation, None
        
    except Exception as e:
        logger.error(f"Translation error for chunk '{chunk[:30]}...': {e}")
        return None, f"Translation failed: {str(e)}"

def translate_with_structure_preservation(text, direction):
    """Translate text while perfectly preserving structure"""
    try:
        # Clean and prepare the text
        cleaned_text = clean_and_prepare_text(text)
        
        if not cleaned_text.strip():
            return "", None
        
        logger.info(f"Starting translation in direction: {direction}")
        logger.info(f"Text length: {len(cleaned_text)} characters")
        
        # For very short text, translate directly
        if len(cleaned_text) <= 300:
            logger.info("Short text - translating directly")
            return translate_chunk_robust(cleaned_text, direction)
        
        # For longer text, preserve structure
        logger.info("Long text - using structure preservation")
        
        # Split into paragraphs first
        paragraphs = cleaned_text.split('\n\n')
        translated_paragraphs = []
        
        for i, paragraph in enumerate(paragraphs):
            paragraph = paragraph.strip()
            
            if not paragraph:
                translated_paragraphs.append('')
                continue
            
            logger.info(f"Processing paragraph {i+1}/{len(paragraphs)}")
            
            # If paragraph is short enough, translate as one piece
            if len(paragraph) <= 300:
                translation, error = translate_chunk_robust(paragraph, direction)
                if error:
                    return None, f"Failed to translate paragraph {i+1}: {error}"
                translated_paragraphs.append(translation)
            else:
                # Split paragraph into chunks
                chunks = split_text_smart(paragraph, max_length=300)
                translated_chunks = []
                
                for j, chunk in enumerate(chunks):
                    logger.info(f"Translating chunk {j+1}/{len(chunks)} of paragraph {i+1}")
                    translation, error = translate_chunk_robust(chunk, direction)
                    if error:
                        return None, f"Failed to translate chunk {j+1} of paragraph {i+1}: {error}"
                    if translation:
                        translated_chunks.append(translation)
                
                # Join chunks with appropriate spacing
                paragraph_translation = ' '.join(translated_chunks)
                translated_paragraphs.append(paragraph_translation)
        
        # Join paragraphs back together
        final_translation = '\n\n'.join(para for para in translated_paragraphs if para.strip())
        
        # Clean up final result
        final_translation = final_translation.strip()
        
        logger.info("Translation completed successfully")
        return final_translation, None
        
    except Exception as e:
        logger.error(f"Structure preservation translation error: {e}")
        return None, f"Translation failed: {str(e)}"

@app.route('/', methods=['GET'])
def status():
    """API status endpoint"""
    return jsonify({
        'status': 'online',
        'name': 'xsukax EN-AR Offline Translator',
        'version': '2.2',
        'message': 'Fixed version with complete translation and proper formatting',
        'available_directions': ['en-ar', 'ar-en'],
        'models_loaded': len(models) == 2,
        'max_text_length': 5000,
        'features': [
            'complete_translation',
            'no_mixed_languages', 
            'structure_preservation',
            'paragraph_spacing',
            'robust_chunking'
        ]
    })

@app.route('/translate', methods=['POST'])
def translate():
    """Main translation endpoint with robust error handling"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({'error': 'No JSON data provided'}), 400
        
        text = data.get('text', '')
        direction = data.get('direction', '').lower()
        
        # Validate input
        if not text or not text.strip():
            return jsonify({'error': 'No text provided'}), 400
        
        if direction not in ['en-ar', 'ar-en']:
            return jsonify({'error': 'Invalid direction. Use "en-ar" or "ar-en"'}), 400
        
        if len(models) != 2:
            return jsonify({'error': 'Models not loaded. Please restart the server.'}), 500
        
        # Check text length limit
        if len(text) > 5000:
            return jsonify({'error': 'Text too long. Maximum 5000 characters allowed.'}), 400
        
        # Perform translation
        logger.info(f"Starting translation request - Direction: {direction}, Length: {len(text)}")
        
        translation, error = translate_with_structure_preservation(text, direction)
        
        if error:
            logger.error(f"Translation failed: {error}")
            return jsonify({'error': error}), 500
        
        if not translation:
            logger.error("Translation returned empty result")
            return jsonify({'error': 'Translation produced empty result'}), 500
        
        # Calculate processing info
        paragraph_count = len([p for p in text.split('\n\n') if p.strip()])
        chunks_processed = max(1, len(split_text_smart(text, max_length=300)))
        
        logger.info(f"Translation successful - Output length: {len(translation)}")
        
        return jsonify({
            'original_text': text,
            'translated_text': translation,
            'direction': direction,
            'success': True,
            'paragraphs_processed': paragraph_count,
            'chunks_processed': chunks_processed,
            'formatting_preserved': True,
            'complete_translation': True,
            'mixed_languages': False
        })
        
    except Exception as e:
        logger.error(f"API error: {e}")
        return jsonify({'error': f'Server error: {str(e)}'}), 500

@app.route('/health', methods=['GET'])
def health():
    """Health check endpoint"""
    return jsonify({
        'healthy': True,
        'models_loaded': len(models) == 2,
        'available_models': list(models.keys()),
        'service': 'xsukax EN-AR Offline Translator',
        'version': '2.2',
        'fixes': [
            'no_mixed_languages',
            'complete_translation',
            'proper_formatting',
            'robust_chunking'
        ]
    })

@app.errorhandler(404)
def not_found(error):
    return jsonify({'error': 'Endpoint not found'}), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({'error': 'Internal server error'}), 500

def main():
    """Main function to start the API server"""
    print("üåê Starting xsukax EN-AR Offline Translator API Server v2.2...")
    print("üîß Fixed version - No mixed languages, complete translation, proper formatting")
    
    # Load translation models
    if not load_models():
        print("‚ùå Failed to load models. Please run install_dependencies.py first.")
        sys.exit(1)
    
    print("\nüöÄ Server starting...")
    print("üì° API will be available at: http://localhost:5000")
    print("üìä Status endpoint: http://localhost:5000/")
    print("üîÑ Translation endpoint: http://localhost:5000/translate")
    print("‚ù§Ô∏è  Health check: http://localhost:5000/health")
    print("üìù Maximum text length: 5000 characters")
    print("üîß Fixed issues:")
    print("   ‚úì No mixed languages in output")
    print("   ‚úì Complete translation guaranteed")
    print("   ‚úì Perfect formatting preservation")
    print("   ‚úì Robust chunking algorithm")
    print("\nüåü Open translator.html in your browser to start translating!")
    print("‚èπÔ∏è  Press Ctrl+C to stop the server\n")
    
    try:
        app.run(
            host='localhost',
            port=5000,
            debug=False,
            threaded=True
        )
    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è  Server stopped by user")
    except Exception as e:
        print(f"\n\nüí• Server error: {e}")
        sys.exit(1)

if __name__ == '__main__':
    main()